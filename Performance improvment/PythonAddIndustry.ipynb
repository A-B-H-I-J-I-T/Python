{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract customer id and email from the table customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                      contact_email\n",
      "0     1055178                    udrub@krebs.com\n",
      "1     1024509                 rwagner@dippel.com\n",
      "2     1035149                veronika82@plath.de\n",
      "3     1017436                karl86@geissler.com\n",
      "4     1073849         neuschaeferbetti@weiss.com\n",
      "...       ...                                ...\n",
      "3696  1021042     nicole66@caldwell-crawford.biz\n",
      "3697  1057037    christopher90@murphy-morrow.com\n",
      "3698  1090115  racheldominguez@stevens-evans.net\n",
      "3699  1025342                 mannlisa@drake.com\n",
      "3700  1036675              jennifer20@palmer.biz\n",
      "\n",
      "[3701 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "\n",
    "# the actual name of your PostgreSQL table\n",
    "table_name = 'customers'\n",
    "column_name1 = 'id'\n",
    "colum_name2 = 'contact_email'\n",
    "\n",
    "# Construct the SQL query to select all columns from the table\n",
    "query = f\"SELECT {column_name1},{colum_name2} FROM {table_name}\"\n",
    "\n",
    "# Use pandas to read the data into a DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n",
    "df_backup = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the domain name and get the Industry values from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDomain(x):\n",
    "    return x.strip().split('@')[1]\n",
    "\n",
    "email = df['contact_email'].apply(extractDomain)\n",
    "email.drop_duplicates(inplace=True)\n",
    "email = email.reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(email)\n",
    "df['industry'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetchIndustry(df,df_merge,batchno,batchsize):\n",
    "    url = \"https://api.apollo.io/v1/organizations/enrich\"\n",
    "    \n",
    "    headers = {\n",
    "        'Cache-Control': 'no-cache',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    df = df.loc[batchsize*batchno:(batchsize*(batchno+1)-1),]\n",
    "    for i in range(batchsize*batchno,batchsize*(batchno+1)):\n",
    "        domain = df.loc[i,'contact_email'] \n",
    "        querystring = {\n",
    "            \"api_key\": \"zXkrJN9Ze5uLOsRwifQzGA\",\n",
    "            \"domain\": domain\n",
    "        }\n",
    "        try:\n",
    "            response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "            if response.status_code == 200 and bool(response.json()):\n",
    "                industry = response.json()\n",
    "                if bool(industry[\"organization\"][\"industry\"]):\n",
    "                    print(i)\n",
    "                    df.loc[i,'industry'] = industry[\"organization\"][\"industry\"]\n",
    "            elif response.status_code == 200:\n",
    "                print(i)\n",
    "                df.loc[i,'industry'] = None\n",
    "            elif response.status_code == 429:\n",
    "                print(\"API requests exhausted\")\n",
    "            else:\n",
    "                print(response.text)\n",
    "        except IOError as e:\n",
    "        # Handle a more general exception (if any other unexpected exception occurs)\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        except Exception as e:\n",
    "        # Print the exact error message\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    df_merge = pd.concat([df_merge, df])\n",
    "    df_merge.to_csv('CustidandIndustryInfo.csv',header=1,index=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge = pd.DataFrame()\n",
    "df_merge = pd.read_csv('CustidandIndustryInfo.csv')\n",
    "batchno = int(len(df_merge)/50)\n",
    "manualbatchno = 32\n",
    "if batchno == manualbatchno:\n",
    "    fetchIndustry(df,df_merge,manualbatchno,50)\n",
    "else:\n",
    "    print(\"check batch no\")\n",
    "\n",
    "#completedbatch 50 : 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,29,30,31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     contact_email                          industry\n",
      "0          rust.de                       hospitality\n",
      "1     bolander.com                      construction\n",
      "2       scheibe.de                       real estate\n",
      "3      steckel.com                               NaN\n",
      "4        plath.org                               NaN\n",
      "...            ...                               ...\n",
      "1595    tessier.fr                   food production\n",
      "1596   monnier.com             industrial automation\n",
      "1597   reynaud.com                               NaN\n",
      "1598     hamel.com  venture capital & private equity\n",
      "1599     dubois.fr                               NaN\n",
      "\n",
      "[1600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "df_merge = pd.read_csv('CustidandIndustryInfo.csv')\n",
    "# df_merge = df_merge.loc[0:249,]\n",
    "# df_merge = df_merge.where(pd.notnull(df_merge), None)\n",
    "# df_merge.loc[599,'industry'] = 'financial services'\n",
    "# df_merge.to_csv('CustidandIndustryInfo.csv',header=1,index=0)\n",
    "print(df_merge)\n",
    "# batchno = len(df_merge)/50\n",
    "# print(int(batchno) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup['domain'] = df_backup['contact_email'].apply(extractDomain)\n",
    "df_insert = pd.merge(df_backup,df_merge,left_on='domain',right_on='contact_email',how=\"left\")\n",
    "df_insert = df_insert[['id','industry']]\n",
    "df_insert.drop_duplicates(inplace=True)\n",
    "df_insert = df_insert.where(pd.notnull(df_insert), None)\n",
    "# df_insert.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column from pandas df\n",
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "table_name = 'customers'\n",
    "new_column_name = 'industry'\n",
    "data_type = 'VARCHAR(255)'  # Adjust the data type based on your requirements\n",
    "\n",
    "# Construct the SQL query to add the new column\n",
    "query = f\"ALTER TABLE {table_name} ADD COLUMN {new_column_name} {data_type};\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(query)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "\n",
    "\n",
    "# Assuming 'primary_key' is the primary key column in both the DataFrame and the PostgreSQL table\n",
    "for index, row in df_insert.iterrows():\n",
    "    primary_key_value = row['id']\n",
    "    new_column_value = row['industry']\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f\"UPDATE {table_name} SET industry = %s WHERE id = %s\"\n",
    "    values = (new_column_value, primary_key_value)\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_insert = df_insert.where(pd.isna(df), None)\n",
    "# print(df_insert)\n",
    "\n",
    "# df_insert.drop_duplicates(inplace=True)\n",
    "# print(len(df_insert))\n",
    "# df_insert[df_insert['id'].isnull()]\n",
    "\n",
    "# print(df)\n",
    "# df.to_csv('CustidandIndustry1.csv',header=1,index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
