{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract customer id and email from the table customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                      contact_email\n",
      "0     1055178                    udrub@krebs.com\n",
      "1     1037261                   juri80@roemer.de\n",
      "2     1047267                 iwan95@soelzer.com\n",
      "3     1050123                 gflantz@stolze.com\n",
      "4     1023075                   nkabus@beier.com\n",
      "...       ...                                ...\n",
      "3696  1021042     nicole66@caldwell-crawford.biz\n",
      "3697  1057037    christopher90@murphy-morrow.com\n",
      "3698  1090115  racheldominguez@stevens-evans.net\n",
      "3699  1025342                 mannlisa@drake.com\n",
      "3700  1036675              jennifer20@palmer.biz\n",
      "\n",
      "[3701 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "\n",
    "# the actual name of your PostgreSQL table\n",
    "table_name = 'customers'\n",
    "column_name1 = 'id'\n",
    "colum_name2 = 'contact_email'\n",
    "\n",
    "# Construct the SQL query to select all columns from the table\n",
    "query = f\"SELECT {column_name1},{colum_name2} FROM {table_name}\"\n",
    "\n",
    "# Use pandas to read the data into a DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n",
    "df_backup = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the domain name and get the Industry values from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDomain(x):\n",
    "    return x.strip().split('@')[1]\n",
    "\n",
    "email = df['contact_email'].apply(extractDomain)\n",
    "email.drop_duplicates(inplace=True)\n",
    "email = email.reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(email)\n",
    "df['industry'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetchIndustry(df,df_merge,batchno,batchsize):\n",
    "    url = \"https://api.apollo.io/v1/organizations/enrich\"\n",
    "    \n",
    "    headers = {\n",
    "        'Cache-Control': 'no-cache',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    df = df.loc[batchsize*batchno:(batchsize*(batchno+1)-1),]\n",
    "    for i in range(batchsize*batchno,batchsize*(batchno+1)):\n",
    "        domain = df.loc[i,'contact_email'] \n",
    "        querystring = {\n",
    "            \"api_key\": \"_JPx70RpHyQKBfUB4kAR0Q\",\n",
    "            \"domain\": domain\n",
    "        }\n",
    "        try:\n",
    "            response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "            if response.status_code == 200 and bool(response.json()):\n",
    "                industry = response.json()\n",
    "                if bool(industry[\"organization\"][\"industry\"]):\n",
    "                    print(i)\n",
    "                    df.loc[i,'industry'] = industry[\"organization\"][\"industry\"]\n",
    "            elif response.status_code == 200:\n",
    "                print(i)\n",
    "                df.loc[i,'industry'] = None\n",
    "            elif response.status_code == 429:\n",
    "                print(\"API requests exhausted\")\n",
    "            else:\n",
    "                print(response.text)\n",
    "        except IOError as e:\n",
    "        # Handle a more general exception (if any other unexpected exception occurs)\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        except Exception as e:\n",
    "        # Print the exact error message\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    df_merge = pd.concat([df_merge, df])\n",
    "    df_merge.to_csv('CustidandIndustryInfo.csv',header=1,index=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850\n",
      "1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhij\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n"
     ]
    }
   ],
   "source": [
    "# df_merge = pd.DataFrame()\n",
    "df_merge = pd.read_csv('CustidandIndustryInfo.csv')\n",
    "batchno = int(len(df_merge)/50)\n",
    "manualbatchno = 38\n",
    "if batchno == manualbatchno:\n",
    "    fetchIndustry(df,df_merge,manualbatchno,50)\n",
    "else:\n",
    "    print(\"check batch no\")\n",
    "\n",
    "#completedbatch 50 : 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34,35,36,37,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             contact_email      industry\n",
      "0                  rust.de   hospitality\n",
      "1             bolander.com  construction\n",
      "2               scheibe.de   real estate\n",
      "3              steckel.com           NaN\n",
      "4                plath.org           NaN\n",
      "...                    ...           ...\n",
      "1845           coppens.org           NaN\n",
      "1846           demeyer.org           NaN\n",
      "1847            dubois.com           NaN\n",
      "1848             smits.biz           NaN\n",
      "1849  horemans-willems.com           NaN\n",
      "\n",
      "[1850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "df_merge = pd.read_csv('CustidandIndustryInfo.csv')\n",
    "# df_merge = df_merge.loc[0:249,]\n",
    "# df_merge = df_merge.where(pd.notnull(df_merge), None)\n",
    "# df_merge.loc[599,'industry'] = 'financial services'\n",
    "# df_merge.to_csv('CustidandIndustryInfo.csv',header=1,index=0)\n",
    "print(df_merge)\n",
    "# batchno = len(df_merge)/50\n",
    "# print(int(batchno) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup['domain'] = df_backup['contact_email'].apply(extractDomain)\n",
    "df_insert = pd.merge(df_backup,df_merge,left_on='domain',right_on='contact_email',how=\"left\")\n",
    "df_insert = df_insert[['id','industry']]\n",
    "df_insert.drop_duplicates(inplace=True)\n",
    "df_insert = df_insert.where(pd.notnull(df_insert), None)\n",
    "# df_insert.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column from pandas df\n",
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "table_name = 'customers'\n",
    "new_column_name = 'industry'\n",
    "data_type = 'VARCHAR(100)'  # Adjust the data type based on your requirements\n",
    "\n",
    "# Construct the SQL query to add the new column\n",
    "query = f\"ALTER TABLE {table_name} ADD COLUMN {new_column_name} {data_type};\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(query)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "\n",
    "\n",
    "# Assuming 'primary_key' is the primary key column in both the DataFrame and the PostgreSQL table\n",
    "for index, row in df_insert.iterrows():\n",
    "    primary_key_value = row['id']\n",
    "    new_column_value = row['industry']\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f\"UPDATE {table_name} SET industry = %s WHERE id = %s\"\n",
    "    values = (new_column_value, primary_key_value)\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_insert = df_insert.where(pd.isna(df), None)\n",
    "# print(df_insert)\n",
    "\n",
    "# df_insert.drop_duplicates(inplace=True)\n",
    "# print(len(df_insert))\n",
    "# df_insert[df_insert['id'].isnull()]\n",
    "\n",
    "# print(df)\n",
    "# df.to_csv('CustidandIndustry1.csv',header=1,index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
