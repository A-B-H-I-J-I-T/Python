{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of api calls allowed for api/v1/organizations/bulk_enrich is 20 times per minute. Please upgrade your plan from https://app.apollo.io/#/settings/plans/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.apollo.io/api/v1/organizations/bulk_enrich\"\n",
    "\n",
    "data = {\n",
    "    \"api_key\": \"ehMfh3qDOoYl174_gXvXeg\",\n",
    "    \"domains\": [\n",
    "        \"plath.de\",\n",
    "        \"outreach.com\",\n",
    "        \"microsoft.com\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, json=data)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information technology & services\n"
     ]
    }
   ],
   "source": [
    "apiresponse = response.json()\n",
    "print(apiresponse[\"organizations\"][2][\"industry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"organization\":{\"id\":\"5da143d870c60500019ef4d6\",\"name\":\"Drake srl\",\"website_url\":\"http://www.drake.com\",\"blog_url\":null,\"angellist_url\":null,\"linkedin_url\":\"http://www.linkedin.com/company/drake-srl\",\"twitter_url\":null,\"facebook_url\":null,\"primary_phone\":{\"number\":\"+1.512.251.2231\",\"source\":\"Account\"},\"languages\":[\"Italian\",\"English\"],\"alexa_ranking\":669419,\"phone\":\"+1.512.251.2231\",\"linkedin_uid\":\"211099\",\"founded_year\":2021,\"publicly_traded_symbol\":null,\"publicly_traded_exchange\":null,\"logo_url\":\"https://zenprospect-production.s3.amazonaws.com/uploads/pictures/64004b7a97a63700016b087f/picture\",\"crunchbase_url\":null,\"primary_domain\":\"drake.com\",\"sanitized_phone\":\"+15122512231\",\"industry\":\"information technology \\u0026 services\",\"keywords\":[\"web agency\",\"cms\",\"database marketing\",\"infocommerce\",\"normalizzazione\",\"siti internet\",\"soluzioni ebusiness\",\"seo\",\"consulenza informatica\",\"microsoft dynamics crm\",\"software house\",\"web\",\"deduplica\",\"sviluppo software\",\"software\",\"ecommerce\",\"crm\"],\"estimated_num_employees\":7,\"industries\":[\"information technology \\u0026 services\",\"internet\",\"computer software\"],\"secondary_industries\":[\"internet\",\"computer software\"],\"snippets_loaded\":true,\"industry_tag_id\":\"5567cd4773696439b10b0000\",\"industry_tag_hash\":{\"information technology \\u0026 services\":\"5567cd4773696439b10b0000\",\"internet\":\"5567cd4d736964397e020000\",\"computer software\":\"5567cd4e7369643b70010000\"},\"retail_location_count\":0,\"raw_address\":\"Via Paracelso, 6, Milan, MI 20129, IT\",\"street_address\":\"6 Via Paracelso\",\"city\":\"Milan\",\"state\":\"Lombardy\",\"postal_code\":\"20129\",\"country\":\"Italy\",\"owned_by_organization_id\":null,\"suborganizations\":[],\"num_suborganizations\":0,\"seo_description\":\"\",\"short_description\":\"Activity closed\",\"total_funding\":null,\"total_funding_printed\":null,\"latest_funding_round_date\":null,\"latest_funding_stage\":null,\"funding_events\":[],\"technology_names\":[\"Google Analytics\",\"Hubspot\",\"Microsoft Office 365\",\"Mobile Friendly\",\"Outlook\",\"YouTube\"],\"current_technologies\":[{\"uid\":\"google_analytics\",\"name\":\"Google Analytics\",\"category\":\"Analytics and Tracking\"},{\"uid\":\"hubspot\",\"name\":\"Hubspot\",\"category\":\"Marketing Automation\"},{\"uid\":\"office_365\",\"name\":\"Microsoft Office 365\",\"category\":\"Other\"},{\"uid\":\"mobile_friendly\",\"name\":\"Mobile Friendly\",\"category\":\"Other\"},{\"uid\":\"outlook\",\"name\":\"Outlook\",\"category\":\"Email Providers\"},{\"uid\":\"youtube\",\"name\":\"YouTube\",\"category\":\"Online Video Platforms\"}],\"org_chart_root_people_ids\":[],\"departmental_head_count\":{\"marketing\":1,\"arts_and_design\":1,\"engineering\":1,\"accounting\":0,\"sales\":0,\"operations\":0,\"finance\":0,\"human_resources\":0,\"information_technology\":0,\"legal\":0,\"business_development\":0,\"product_management\":0,\"consulting\":0,\"education\":0,\"administrative\":0,\"media_and_commmunication\":0,\"entrepreneurship\":0,\"support\":0,\"data_science\":0}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.apollo.io/v1/organizations/enrich\"\n",
    "\n",
    "querystring = {\n",
    "    \"api_key\": \"zXkrJN9Ze5uLOsRwifQzGA\",\n",
    "    \"domain\": \"drake.com\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# print(response.json())\n",
    "\n",
    "# Specify the file path where you want to save the JSON file\n",
    "file_path = \"output.json\"\n",
    "\n",
    "# Write data to the JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(response.json(), json_file, indent=4)\n",
    "\n",
    "print(f\"Data has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def extractDomain(x):\n",
    "#     return x.strip().split('@')[1]\n",
    "# email = df['contact_email'].apply(extractDomain)\n",
    "df['contact_email'] = df['contact_email'].astype(str)\n",
    "domain = df['contact_email'].str.split('@').str[1]\n",
    "domain.drop_duplicates(inplace=True)\n",
    "domain = domain.reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(domain)\n",
    "df['industry'] = None\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sporting goods\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "print(data[\"organization\"][\"industry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 9.2 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#connection to postgres\n",
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "\n",
    "# Replace these values with your PostgreSQL connection details\n",
    "db_params = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': '!q2W3e4r',\n",
    "}\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "cursor = connection.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Database Version: PostgreSQL 16.1, compiled by Visual C++ build 1937, 64-bit\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "\n",
    "def test_postgres_connection():\n",
    "    try:\n",
    "        # Replace these values with your PostgreSQL connection details\n",
    "        connection = psycopg2.connect(\n",
    "            host='localhost',\n",
    "            database='postgres',\n",
    "            user='postgres',\n",
    "            password='!q2W3e4r'\n",
    "        )\n",
    "\n",
    "        # Open a cursor to perform database operations\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Execute a simple query to test the connection\n",
    "        cursor.execute(\"SELECT version();\")\n",
    "\n",
    "        # Fetch the result\n",
    "        db_version = cursor.fetchone()\n",
    "        print(f\"PostgreSQL Database Version: {db_version[0]}\")\n",
    "\n",
    "        # Close communication with the database\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Call the function to test the connection\n",
    "test_postgres_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manualbatchno = 56\n",
    "# if batchno == manualbatchno:\n",
    "#     fetchIndustry(df,df_merge,manualbatchno,50)\n",
    "# else:\n",
    "#     print(\"check batch no\")\n",
    "\n",
    "# completedbatch 50 : 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45\n",
    "# 46, 47, 48, 49, 50, 51, 52\n",
    "\n",
    "\n",
    "# df_insert = df_insert.where(pd.isna(df), None)\n",
    "# print(df_insert)\n",
    "\n",
    "# df_insert.drop_duplicates(inplace=True)\n",
    "# print(len(df_insert))\n",
    "# df_insert[df_insert['id'].isnull()]\n",
    "\n",
    "# print(df)\n",
    "# df.to_csv('CustidandIndustry1.csv',header=1,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sid                   location  year\n",
      "0  001-F           Wembley (London)  2013\n",
      "1  002-F  Estadio da Luz (Lissabon)  2020\n",
      "2  003-F    Olympiastadion (Berlin)  2015\n",
      "3  004-F    Olympiastadion (Berlin)  2021\n",
      "4  005-F    Olympiastadion (Berlin)  2018\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Replace these values with your PostgreSQL connection details\n",
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "table_name = 'Sportsgame'\n",
    "\n",
    "# Construct the SQL query to select all columns from the table\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Use pandas to read the data into a DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sid         game\n",
      "0  001-F     Football\n",
      "1  002-F      Cricket\n",
      "2  003-F       Hockey\n",
      "3  004-F  Tabletennis\n",
      "4  005-F    Billiards\n"
     ]
    }
   ],
   "source": [
    "# df.drop(columns=\"game\",inplace=True)\n",
    "game = [\"Football\",\"Cricket\",\"Hockey\",\"Tabletennis\",\"Billiards\"]\n",
    "df[\"game\"] = game\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column from pandas df\n",
    "\n",
    "db_params = {\n",
    "            \"host\":'localhost',\n",
    "            \"database\":'postgres',\n",
    "            \"user\":'postgres',\n",
    "            \"password\":'!q2W3e4r'\n",
    "            }\n",
    "\n",
    "connection = psycopg2.connect(**db_params)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "table_name = 'Sportsgame'\n",
    "new_column_name = 'game'\n",
    "data_type = 'VARCHAR(55)'  # Adjust the data type based on your requirements\n",
    "\n",
    "# Construct the SQL query to add the new column\n",
    "query = f\"ALTER TABLE {table_name} ADD COLUMN {new_column_name} {data_type};\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(query)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "# Replace 'your_table_name' with the actual name of your PostgreSQL table\n",
    "\n",
    "\n",
    "# Assuming 'primary_key' is the primary key column in both the DataFrame and the PostgreSQL table\n",
    "for index, row in df.iterrows():\n",
    "    primary_key_value = row['sid']\n",
    "    new_column_value = row['game']\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f\"UPDATE {table_name} SET game = %s WHERE sid = %s\"\n",
    "    values = (new_column_value, primary_key_value)\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# extra work\n",
    "def extractDomain(x):\n",
    "    return x.strip().split('@')[1]\n",
    "\n",
    "email = df['contact_email'].apply(extractDomain)\n",
    "email.drop_duplicates(inplace=True)\n",
    "email = email.reset_index(drop=True)\n",
    "print(email.isnull().sum())\n",
    "print(len(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.apollo.io/api/v1/organizations/bulk_enrich\"\n",
    "\n",
    "headers = {\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "df_domain = pd.read_csv('industry.csv',header=0)\n",
    "df_backup = df_domain.copy()\n",
    "df_domain = df_domain[df_domain['industry'].isnull()]\n",
    "df_domain = df_domain.reset_index(drop=True)\n",
    "\n",
    "for i in range(0,210,10):\n",
    "        domain = df_domain[\"contact_email\"][i:i+10].tolist()\n",
    "        data = {\n",
    "            \"api_key\": \"ehMfh3qDOoYl174_gXvXeg\",\n",
    "            \"domains\": domain\n",
    "        }\n",
    "        try:\n",
    "            response = requests.request(\"POST\", url, headers=headers, json=data)\n",
    "            if bool(response.json()):\n",
    "                if bool(response.json()['organizations']):\n",
    "                    org_response = response.json()['organizations']\n",
    "                    for j in range(0,10):\n",
    "                        if bool(org_response[j]):\n",
    "                            industry = org_response[j][\"industry\"]\n",
    "                            domain_name = org_response[j][\"primary_domain\"]\n",
    "                            if bool(industry):\n",
    "                                idx_df = df_backup[df_backup['contact_email']== domain_name].index\n",
    "                                df_backup.iloc[idx_df,1] = industry\n",
    "                            else:\n",
    "                                idx_df = df_backup[df_backup['contact_email']== domain_name].index\n",
    "                                df_backup.iloc[idx_df,1] = \"No Industry Information\"\n",
    "        except IOError as e:\n",
    "        # Handle a more general exception (if any other unexpected exception occurs)\n",
    "            errormsg = str(e)\n",
    "            print(f\"Unexpected error: {errormsg}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
